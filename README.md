# Machine Learning Quality Evaluation for Machine Learning Systems 

## Thesis Objective

Evaluating the quality of ML classification algorithms for 17 different classifiers from Spark ML, Keras, and Scikit-learn to detect or minimize ML bugs at an early stage before a model is deployed. This can be achieved by testing the Code, the Model, and the Data and evaluating the individual classifiers using ML quality attributes using three popular classification datasets 
## Testing Approaches
We took an inspiration behavioral model testing from NLP models using

1.  Model Pre-train tests to ensure data quality
2.  Model Post-train tests to evaluate the behavior of the trained models
  * Unit testing(Minimum Functionality test)
  * Invaraint tests  
  * Directional expectation tests
4.  dd 

## Scikit-Learn Classifiers
**We have choosen 8 classifiers from the Scikit-Learn Machine Learning Library**
1.  LinearSVC
2.  LogisticRegression
3.  DecisionTreeClassifier
4.  RandomForestClassifier
5.  GaussianNB
6.  GradientBoostingClassifier
7.  OneVsRest
8.  MLPClassifier
## Spark ML classifiers
**We have choosen 8 classifiers from Spark ML package**
1. LinearSVC
2. LogisticRegression
3. DecisionTreeClassifier
4. RandomForestClassifier
5. NaiveBayes(modeltype='Gussian')
6. GBTClassifier
7. OneVsRestClassifier
8. MLPClassifier

## Keras Classifier 
**We selected the general keras classifiers from the Keras Deep Learning Library**
* Keras Classifier


## Evaluation Metrics

## Set of Tools 
